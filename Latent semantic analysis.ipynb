{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data visualisation and manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "import seaborn as sns\n",
    "#configure\n",
    "# sets matplotlib to inline and displays graphs below the corressponding cell.\n",
    "%matplotlib inline  \n",
    "style.use('fivethirtyeight')\n",
    "sns.set(style='whitegrid',color_codes=True)\n",
    "\n",
    "#import nltk\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "\n",
    "#preprocessing\n",
    "from nltk.corpus import stopwords  #stopwords\n",
    "from nltk import word_tokenize,sent_tokenize # tokenizing\n",
    "from nltk.stem import PorterStemmer,LancasterStemmer  # using the Porter Stemmer and Lancaster Stemmer and others\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer  # lammatizer from WordNet\n",
    "\n",
    "# for named entity recognition (NER)\n",
    "from nltk import ne_chunk\n",
    "\n",
    "# vectorizers for creating the document-term-matrix (DTM)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "\n",
    "#stop-words\n",
    "stop_words=set(nltk.corpus.stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(r'D:\\\\CoronaTweets\\\\corona_tweet41.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>user_id</th>\n",
       "      <th>user_screen_name</th>\n",
       "      <th>user_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1305389523602472962</td>\n",
       "      <td>@YoWaybes Eww ðŸ˜· gonna need a mask for that thi...</td>\n",
       "      <td>1221168153008279552</td>\n",
       "      <td>LmaoNoxy</td>\n",
       "      <td>Noxy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1305389500504272897</td>\n",
       "      <td>Great words by @supriya_sule from @NCPspeaks t...</td>\n",
       "      <td>1267079862084227073</td>\n",
       "      <td>mannykapron</td>\n",
       "      <td>Manish kapruwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1305389495890653184</td>\n",
       "      <td>Al die Corona, alleen maar voor een lagere sne...</td>\n",
       "      <td>14183892</td>\n",
       "      <td>hoxha</td>\n",
       "      <td>hoxma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1305389473195122688</td>\n",
       "      <td>ðŸ‘‰Increasing Corona Cases\\nðŸ‘‰ Unemployment\\nðŸ‘‰Fal...</td>\n",
       "      <td>2186187964</td>\n",
       "      <td>Ranveer_Chelsea</td>\n",
       "      <td>RANVEER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1305389472163540992</td>\n",
       "      <td>@realDonaldTrump Donald Trump has already prov...</td>\n",
       "      <td>3108330785</td>\n",
       "      <td>wizzzzdoom</td>\n",
       "      <td>Hussein Barrak Obama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id                                               text  \\\n",
       "0  1305389523602472962  @YoWaybes Eww ðŸ˜· gonna need a mask for that thi...   \n",
       "1  1305389500504272897  Great words by @supriya_sule from @NCPspeaks t...   \n",
       "2  1305389495890653184  Al die Corona, alleen maar voor een lagere sne...   \n",
       "3  1305389473195122688  ðŸ‘‰Increasing Corona Cases\\nðŸ‘‰ Unemployment\\nðŸ‘‰Fal...   \n",
       "4  1305389472163540992  @realDonaldTrump Donald Trump has already prov...   \n",
       "\n",
       "               user_id user_screen_name             user_name  \n",
       "0  1221168153008279552         LmaoNoxy                  Noxy  \n",
       "1  1267079862084227073      mannykapron       Manish kapruwan  \n",
       "2             14183892            hoxha                 hoxma  \n",
       "3           2186187964  Ranveer_Chelsea               RANVEER  \n",
       "4           3108330785       wizzzzdoom  Hussein Barrak Obama  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['id','user_id','user_screen_name','user_name'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@YoWaybes Eww ðŸ˜· gonna need a mask for that thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great words by @supriya_sule from @NCPspeaks t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Al die Corona, alleen maar voor een lagere sne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ðŸ‘‰Increasing Corona Cases\\nðŸ‘‰ Unemployment\\nðŸ‘‰Fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@realDonaldTrump Donald Trump has already prov...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @YoWaybes Eww ðŸ˜· gonna need a mask for that thi...\n",
       "1  Great words by @supriya_sule from @NCPspeaks t...\n",
       "2  Al die Corona, alleen maar voor een lagere sne...\n",
       "3  ðŸ‘‰Increasing Corona Cases\\nðŸ‘‰ Unemployment\\nðŸ‘‰Fal...\n",
       "4  @realDonaldTrump Donald Trump has already prov..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(headline):\n",
    "  le=WordNetLemmatizer()\n",
    "  word_tokens=word_tokenize(headline)\n",
    "  tokens=[le.lemmatize(w) for w in word_tokens if w not in stop_words and len(w)>3]\n",
    "  cleaned_text=\" \".join(tokens)\n",
    "  return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text']=df['text'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>YoWaybes need mask thing already corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great word supriya_sule NCPspeaks today Indian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Corona alleen maar voor lagere snelheid Review...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ðŸ‘‰Increasing Corona Cases Unemployment ðŸ‘‰Falling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>realDonaldTrump Donald Trump already proven ha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0            YoWaybes need mask thing already corona\n",
       "1  Great word supriya_sule NCPspeaks today Indian...\n",
       "2  Corona alleen maar voor lagere snelheid Review...\n",
       "3  ðŸ‘‰Increasing Corona Cases Unemployment ðŸ‘‰Falling...\n",
       "4  realDonaldTrump Donald Trump already proven ha..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect =TfidfVectorizer(stop_words=stop_words,max_features=1000,ngram_range = (1,3)) # to play with. min_df,max_df,max_features etc...\n",
    "vect_text=vect.fit_transform(df['text'])\n",
    "#vectorizer = TfidfVectorizer(ngram_range = (1,3)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 1000)\n",
      "  (0, 164)\t0.12540249430407818\n",
      "  (0, 53)\t0.5220990919426999\n",
      "  (0, 863)\t0.5088718787872414\n",
      "  (0, 548)\t0.4402108296873329\n",
      "  (0, 605)\t0.5088718787872414\n",
      "  (1, 615)\t0.36278174370270677\n",
      "  (1, 440)\t0.09169256435105191\n",
      "  (1, 614)\t0.36278174370270677\n",
      "  (1, 142)\t0.09169256435105191\n",
      "  (1, 439)\t0.09169256435105191\n",
      "  (1, 611)\t0.30576703089252477\n",
      "  (1, 280)\t0.38068229662866276\n",
      "  (1, 878)\t0.2848305886998597\n",
      "  (1, 837)\t0.38068229662866276\n",
      "  (1, 978)\t0.38068229662866276\n",
      "  (1, 396)\t0.31965177844159326\n",
      "  (2, 818)\t0.43846527661663537\n",
      "  (2, 361)\t0.6036267684437622\n",
      "  (2, 753)\t0.6036267684437622\n",
      "  (2, 440)\t0.1453918051869288\n",
      "  (2, 142)\t0.1453918051869288\n",
      "  (2, 439)\t0.1453918051869288\n",
      "  (2, 164)\t0.12490524004715525\n",
      "  (3, 704)\t0.3959312623932995\n",
      "  (3, 848)\t0.3959312623932995\n",
      "  :\t:\n",
      "  (498, 786)\t0.44656488248640824\n",
      "  (498, 516)\t0.48724794690916406\n",
      "  (498, 838)\t0.4320444682870934\n",
      "  (498, 771)\t0.3590694389610643\n",
      "  (498, 164)\t0.10082359655466935\n",
      "  (499, 752)\t0.27371696885986846\n",
      "  (499, 118)\t0.27371696885986846\n",
      "  (499, 479)\t0.27371696885986846\n",
      "  (499, 237)\t0.27371696885986846\n",
      "  (499, 683)\t0.27371696885986846\n",
      "  (499, 236)\t0.27371696885986846\n",
      "  (499, 660)\t0.27371696885986846\n",
      "  (499, 886)\t0.27371696885986846\n",
      "  (499, 514)\t0.27371696885986846\n",
      "  (499, 682)\t0.2298350006305795\n",
      "  (499, 885)\t0.24270579901337827\n",
      "  (499, 233)\t0.20171126233797904\n",
      "  (499, 290)\t0.19113530855507224\n",
      "  (499, 110)\t0.15896200425389667\n",
      "  (499, 202)\t0.22456542754968684\n",
      "  (499, 849)\t0.21169462916688805\n",
      "  (499, 440)\t0.06592849471442605\n",
      "  (499, 142)\t0.06592849471442605\n",
      "  (499, 439)\t0.06592849471442605\n",
      "  (499, 164)\t0.05663877993443697\n"
     ]
    }
   ],
   "source": [
    "print(vect_text.shape)\n",
    "print(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "lsa_model = TruncatedSVD(n_components=10, algorithm='randomized', n_iter=10, random_state=42)\n",
    "\n",
    "lsa_top=lsa_model.fit_transform(vect_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.11406503 -0.03811296  0.11911714 ...  0.02627249 -0.09427033\n",
      "  -0.06186018]\n",
      " [ 0.13310887 -0.07410099 -0.09029538 ... -0.00098959 -0.01359138\n",
      "  -0.19445678]\n",
      " [ 0.22416288 -0.10098913 -0.00213665 ... -0.0244589  -0.03790002\n",
      "  -0.00308639]\n",
      " ...\n",
      " [ 0.12570182 -0.03124555  0.16368946 ... -0.01384268 -0.01358427\n",
      "  -0.12330394]\n",
      " [ 0.09674367 -0.02743044  0.13371369 ... -0.01501533 -0.04372872\n",
      "  -0.10671349]\n",
      " [ 0.22524684  0.13150344 -0.03736298 ... -0.05591091 -0.04736634\n",
      "  -0.13834789]]\n",
      "(500, 10)\n"
     ]
    }
   ],
   "source": [
    "print(lsa_top)\n",
    "print(lsa_top.shape)  # (no_of_doc*no_of_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document 0 :\n",
      "Topic  0  :  11.406502992014133\n",
      "Topic  1  :  -3.811296009449048\n",
      "Topic  2  :  11.91171360692925\n",
      "Topic  3  :  -1.1093390254299493\n",
      "Topic  4  :  -2.1362754280165506\n",
      "Topic  5  :  5.521906755786332\n",
      "Topic  6  :  0.6997987565650933\n",
      "Topic  7  :  2.6272494584871664\n",
      "Topic  8  :  -9.427032710776317\n",
      "Topic  9  :  -6.186017590855605\n"
     ]
    }
   ],
   "source": [
    "l=lsa_top[0]\n",
    "print(\"Document 0 :\")\n",
    "for i,topic in enumerate(l):\n",
    "  print(\"Topic \",i,\" : \",topic*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: \n",
      "corona co http virus case total cases odisha district people \n",
      "\n",
      "Topic 1: \n",
      "cases total odisha district case virus q4my3bdkor khordha deaths 2010 \n",
      "\n",
      "Topic 2: \n",
      "corona like school back miss death shit test realdonaldtrump much \n",
      "\n",
      "Topic 3: \n",
      "virus pandemic making lost weekly profit corona help business sbhdkzpswz \n",
      "\n",
      "Topic 4: \n",
      "people virus trump like realdonaldtrump gopchairwoman even know president real \n",
      "\n",
      "Topic 5: \n",
      "people india today deaths like recovered update active confirmed rahulgandhi \n",
      "\n",
      "Topic 6: \n",
      "like year last even tell unemployment lost gdp unplanned making \n",
      "\n",
      "Topic 7: \n",
      "year last highest unemployment gdp unplanned rate virus lockdown spreadin \n",
      "\n",
      "Topic 8: \n",
      "realdonaldtrump like trump deaths active confirmed india 4850887 79784 990502 \n",
      "\n",
      "Topic 9: \n",
      "time like recovered work people deaths update virus 4850887 79784 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = vect.get_feature_names()\n",
    "\n",
    "for i, comp in enumerate(lsa_model.components_):\n",
    "    vocab_comp = zip(vocab, comp)\n",
    "    sorted_words = sorted(vocab_comp, key= lambda x:x[1], reverse=True)[:10]\n",
    "    print(\"Topic \"+str(i)+\": \")\n",
    "    for t in sorted_words:\n",
    "        print(t[0],end=\" \")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
